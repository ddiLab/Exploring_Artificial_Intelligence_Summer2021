{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "472e9d79",
   "metadata": {},
   "source": [
    "# Genre Classification\n",
    "\n",
    "In this notebook, you'll create a machine learning model to classify the music genre of songs. You will customize the dataset you use and the features your model will train on, and you will decide how to build and train your model in a way to maximize efficiency and accuracy.\n",
    "\n",
    "To begin, run the cell below. As always, this first cell loads the function and data necessary to run our code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c722878",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../utils')\n",
    "import genres_full as gs\n",
    "\n",
    "artists, tracks, data = gs.load_metadata('/data/Genres_Full/tracks.csv') # Path to fma metadata\n",
    "full_features = gs.load_features('/data/Genres_Full/fma_small.csv', data) # Path to fma features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4088d4b",
   "metadata": {},
   "source": [
    "## 1. Dataset\n",
    "\n",
    "Before we can build and train a model, we need to prepare the data it's going to be using.\n",
    "\n",
    "First, let's split the dataset up into subsets for training, validating, and testing the model. The training data is exactly what it sounds like - it's the data that the model uses to learn how features differ across different music genres. The validation data is used to test the model's accuracy at identifying genres at checkpoints throughout the training process. Finally, the test set is used to guage the accuracy of the model once it has completed the training process.\n",
    "\n",
    "Run the cell below. Then, using the sliders that appear, select how many songs from the dataset to use for the training, validation, and test sets. **The dataset contains 7997 songs in total, so your subsets will (at most) total 7997 songs together.** You are not required to use all 7997 songs, but you can't go over. Each subset must have at least 1 song in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ea7ea23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a1142ead93b4382a4d13570015d43e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='Training', max=7995, min=1), IntSlider(value=1, descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training, validation, test = gs.select_split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1720d57a",
   "metadata": {},
   "source": [
    "Now let's decide what we want our training subset to look like. We're going to be training our model to classify eight different genres: electronic, experimental, folk, hip-hop, instrumental, international, pop, and rock. How many songs for each genre should we have in our training set?\n",
    "\n",
    "Run the cell below. Next, use the sliders that appear to select how many songs you want per genre in your training set (you can also click on the number to type instead). Each genre has approximately 1000 songs in it, though keep in mind that some of these songs will be reserved for your validation and test sets. **Keep an eye on the total amount of songs in your training set - don't go over the limit you set for your training set previously.** A warning message will pop up to let you know if you need to dial back your selections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ef50b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 3203\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6baba15b8084a22837fd6e7710e075b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='electronic', max=999), IntSlider(value=0, description='e…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "genres = gs.select_dataset(training.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f84b70d",
   "metadata": {},
   "source": [
    "## 2. Features\n",
    "\n",
    "There are a number of different features we can extract from audio data. We might describe these features as being \"low-level,\" meaning that they describe attributes that are much more related to the basic structure of sound waves, as opposed to high-level features that are closer related to our perception of sounds, like mood and genre. Often times, we can use these low-level features to describe (or predict, in our case) high-level features.\n",
    "\n",
    "Now that you've finalized your dataset, you must decide which features to extract from the data so that your model can train on them. you can select up to 7 distinct features to extract from your dataset. Don't worry too much about understanding what they mean - since low-level features are so far away from the high-level features our brains are built to perceive, they might sound complicated or unintuitive. All you really need to know is that these are different ways of describing audio information in a way computers are able to easily understand. Don't be afraid to experiment and try different combinations of features at random.\n",
    "\n",
    "Here are some very brief descriptions of each of the features we'll be collecting:\n",
    "- **Chroma**: Measures how much each of the 12 pitch classes (A, Bb, B, C, etc.) are present in the audio signal.\n",
    "- **Root-mean square energy**: Kind of like the \"average\" energy, or loudness, of the audio signal.\n",
    "- **Spectral centroid**: Indicates which frequency in the audio signal has the most energy, kind of like the \"center of gravity\" of the signal.\n",
    "- **Spectral bandwith**: Describes how other frequencies are related to the spectral centroid, making it useful for describing the timbre, or sound quality, of an audio signal.\n",
    "- **Spectral rolloff**: A way of measuring the shape of an audio signal.\n",
    "- **Zero-crossing rate**: Useful for distinguishing pitched signals from percussive, or unpitched, signals.\n",
    "- **Mel-frequency cepstral coefficients**: Analyze the frequency content of an audio signal using methods similar to how our brains perceive frequency and pitch.\n",
    "\n",
    "Run the cell below. For each feature you want to extract from your data, click the corresponding checkbox. Once you're satisfied with your selection, click the \"Extract features\" button to extract your features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f864b8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "959f32c1177f447a86087c8c164c7f26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Checkbox(value=False, description='chroma'), Checkbox(value=False, description='rmse'), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "features = gs.select_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f71fa1",
   "metadata": {},
   "source": [
    "## 3. Building the Model\n",
    "Next, let's make some final decisions about your model. One parameter we can adjust is the number of layers built in to your model. The neurons of a neural network model are grouped into layers. More layers means more neurons, though an increased layer count also comes at the cost of more computational resources and more time to train.\n",
    "\n",
    "We can also adjust the amount of time our model spends training. The training process is broken up into different segments, which are called epochs. Training a model for more epochs gives it more time to learn the data and make connections, though training for too many epochs can often lead to diminishing returns. \n",
    "\n",
    "Run the cell below. Then, using the sliders that appear, select the amount of layers and epochs you want for your model. You can select anywhere between 2 and 8 layers, as well as between 1 and 500 epochs. **Having a lot of both layers and epochs is computationally expensive, so be mindful of how you balance the two.** The maximum value you can select for each slider will get smaller as the other slider increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0b454f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d55a845f4854c50a1448336e5176f7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=4, description='Layers', max=8, min=2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95ceec97acd145e9bceb7759223c81b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=100, description='Epochs', max=500, min=1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "layers, epochs = gs.select_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd103b05",
   "metadata": {},
   "source": [
    "## 4. Training the Model\n",
    "Now the time has finally come to train your model! Once you've finished setting all your desired parameters, run the cell below. It'll process the options you've submitted, then it will build and train your model using the training and validation sets you made. The model will print out a progress bar and stats for each epoch it completes until it runs through all of them. Depending on the parameters you've chosen, it may take a few minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39146fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "22/22 [==============================] - 14s 25ms/step - loss: 2.0137 - accuracy: 0.2156 - val_loss: 1.9699 - val_accuracy: 0.1999\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.8518 - accuracy: 0.3061 - val_loss: 1.9435 - val_accuracy: 0.1963\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.8215 - accuracy: 0.3147 - val_loss: 1.9401 - val_accuracy: 0.2014\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.8196 - accuracy: 0.3065 - val_loss: 1.9424 - val_accuracy: 0.2056\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7970 - accuracy: 0.3141 - val_loss: 1.9270 - val_accuracy: 0.2087\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7855 - accuracy: 0.3218 - val_loss: 1.9549 - val_accuracy: 0.2107\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7861 - accuracy: 0.3193 - val_loss: 1.9145 - val_accuracy: 0.2184\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7831 - accuracy: 0.3170 - val_loss: 1.9406 - val_accuracy: 0.2112\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7679 - accuracy: 0.3224 - val_loss: 1.9258 - val_accuracy: 0.2195\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1.7887 - accuracy: 0.3152 - val_loss: 1.9073 - val_accuracy: 0.2251\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1.7720 - accuracy: 0.3215 - val_loss: 1.9274 - val_accuracy: 0.2200\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7585 - accuracy: 0.3273 - val_loss: 1.9043 - val_accuracy: 0.2231\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7807 - accuracy: 0.3319 - val_loss: 1.9125 - val_accuracy: 0.2272\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7630 - accuracy: 0.3217 - val_loss: 1.9270 - val_accuracy: 0.2138\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7876 - accuracy: 0.3118 - val_loss: 1.9185 - val_accuracy: 0.2164\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7749 - accuracy: 0.3316 - val_loss: 1.9339 - val_accuracy: 0.2174\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7765 - accuracy: 0.3295 - val_loss: 1.9141 - val_accuracy: 0.2226\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7777 - accuracy: 0.3078 - val_loss: 1.9140 - val_accuracy: 0.2231\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1.7619 - accuracy: 0.3211 - val_loss: 1.9509 - val_accuracy: 0.2107\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7703 - accuracy: 0.3322 - val_loss: 1.8932 - val_accuracy: 0.2406\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7649 - accuracy: 0.3229 - val_loss: 1.9239 - val_accuracy: 0.2215\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7702 - accuracy: 0.3124 - val_loss: 1.9090 - val_accuracy: 0.2231\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7737 - accuracy: 0.3106 - val_loss: 1.9358 - val_accuracy: 0.2169\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7716 - accuracy: 0.3243 - val_loss: 1.9005 - val_accuracy: 0.2349\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7674 - accuracy: 0.3175 - val_loss: 1.8982 - val_accuracy: 0.2334\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7617 - accuracy: 0.3289 - val_loss: 1.9017 - val_accuracy: 0.2308\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7549 - accuracy: 0.3410 - val_loss: 1.9033 - val_accuracy: 0.2313\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1.7679 - accuracy: 0.3187 - val_loss: 1.9340 - val_accuracy: 0.2246\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7523 - accuracy: 0.3338 - val_loss: 1.9048 - val_accuracy: 0.2303\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7662 - accuracy: 0.3209 - val_loss: 1.9085 - val_accuracy: 0.2298\n",
      "Epoch 31/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7577 - accuracy: 0.3291 - val_loss: 1.9297 - val_accuracy: 0.2221\n",
      "Epoch 32/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7452 - accuracy: 0.3363 - val_loss: 1.9120 - val_accuracy: 0.2272\n",
      "Epoch 33/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7561 - accuracy: 0.3327 - val_loss: 1.9192 - val_accuracy: 0.2257\n",
      "Epoch 34/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7542 - accuracy: 0.3205 - val_loss: 1.9406 - val_accuracy: 0.2179\n",
      "Epoch 35/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7710 - accuracy: 0.3253 - val_loss: 1.9081 - val_accuracy: 0.2262\n",
      "Epoch 36/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7635 - accuracy: 0.3325 - val_loss: 1.9326 - val_accuracy: 0.2298\n",
      "Epoch 37/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7546 - accuracy: 0.3200 - val_loss: 1.9271 - val_accuracy: 0.2241\n",
      "Epoch 38/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7487 - accuracy: 0.3328 - val_loss: 1.9242 - val_accuracy: 0.2257\n",
      "Epoch 39/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7565 - accuracy: 0.3335 - val_loss: 1.9211 - val_accuracy: 0.2257\n",
      "Epoch 40/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7456 - accuracy: 0.3344 - val_loss: 1.9459 - val_accuracy: 0.2231\n",
      "Epoch 41/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7675 - accuracy: 0.3278 - val_loss: 1.9178 - val_accuracy: 0.2349\n",
      "Epoch 42/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7433 - accuracy: 0.3288 - val_loss: 1.9257 - val_accuracy: 0.2215\n",
      "Epoch 43/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7362 - accuracy: 0.3293 - val_loss: 1.9175 - val_accuracy: 0.2313\n",
      "Epoch 44/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7313 - accuracy: 0.3409 - val_loss: 1.9143 - val_accuracy: 0.2318\n",
      "Epoch 45/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7423 - accuracy: 0.3324 - val_loss: 1.9049 - val_accuracy: 0.2287\n",
      "Epoch 46/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7654 - accuracy: 0.3238 - val_loss: 1.9186 - val_accuracy: 0.2329\n",
      "Epoch 47/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7553 - accuracy: 0.3267 - val_loss: 1.9314 - val_accuracy: 0.2257\n",
      "Epoch 48/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7488 - accuracy: 0.3337 - val_loss: 1.9208 - val_accuracy: 0.2231\n",
      "Epoch 49/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7516 - accuracy: 0.3307 - val_loss: 1.9265 - val_accuracy: 0.2282\n",
      "Epoch 50/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7533 - accuracy: 0.3298 - val_loss: 1.9131 - val_accuracy: 0.2354\n",
      "Epoch 51/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7254 - accuracy: 0.3444 - val_loss: 1.9186 - val_accuracy: 0.2318\n",
      "Epoch 52/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7470 - accuracy: 0.3420 - val_loss: 1.9085 - val_accuracy: 0.2365\n",
      "Epoch 53/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7461 - accuracy: 0.3244 - val_loss: 1.9238 - val_accuracy: 0.2318\n",
      "Epoch 54/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7609 - accuracy: 0.3314 - val_loss: 1.9191 - val_accuracy: 0.2246\n",
      "Epoch 55/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7486 - accuracy: 0.3364 - val_loss: 1.9177 - val_accuracy: 0.2365\n",
      "Epoch 56/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7453 - accuracy: 0.3254 - val_loss: 1.9215 - val_accuracy: 0.2282\n",
      "Epoch 57/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1.7501 - accuracy: 0.3272 - val_loss: 1.9132 - val_accuracy: 0.2365\n",
      "Epoch 58/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7551 - accuracy: 0.3107 - val_loss: 1.9240 - val_accuracy: 0.2267\n",
      "Epoch 59/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7343 - accuracy: 0.3412 - val_loss: 1.9169 - val_accuracy: 0.2293\n",
      "Epoch 60/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7286 - accuracy: 0.3393 - val_loss: 1.9221 - val_accuracy: 0.2313\n",
      "Epoch 61/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7306 - accuracy: 0.3363 - val_loss: 1.9122 - val_accuracy: 0.2313\n",
      "Epoch 62/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7502 - accuracy: 0.3237 - val_loss: 1.9041 - val_accuracy: 0.2365\n",
      "Epoch 63/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7282 - accuracy: 0.3346 - val_loss: 1.9145 - val_accuracy: 0.2360\n",
      "Epoch 64/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7518 - accuracy: 0.3202 - val_loss: 1.9132 - val_accuracy: 0.2421\n",
      "Epoch 65/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7359 - accuracy: 0.3361 - val_loss: 1.9338 - val_accuracy: 0.2344\n",
      "Epoch 66/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7156 - accuracy: 0.3484 - val_loss: 1.8989 - val_accuracy: 0.2396\n",
      "Epoch 67/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7486 - accuracy: 0.3216 - val_loss: 1.9390 - val_accuracy: 0.2257\n",
      "Epoch 68/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7331 - accuracy: 0.3323 - val_loss: 1.8877 - val_accuracy: 0.2447\n",
      "Epoch 69/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7300 - accuracy: 0.3392 - val_loss: 1.9119 - val_accuracy: 0.2257\n",
      "Epoch 70/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7467 - accuracy: 0.3277 - val_loss: 1.9201 - val_accuracy: 0.2360\n",
      "Epoch 71/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7359 - accuracy: 0.3226 - val_loss: 1.9199 - val_accuracy: 0.2251\n",
      "Epoch 72/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7268 - accuracy: 0.3474 - val_loss: 1.9143 - val_accuracy: 0.2391\n",
      "Epoch 73/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7238 - accuracy: 0.3331 - val_loss: 1.9116 - val_accuracy: 0.2344\n",
      "Epoch 74/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7393 - accuracy: 0.3233 - val_loss: 1.9209 - val_accuracy: 0.2334\n",
      "Epoch 75/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7205 - accuracy: 0.3401 - val_loss: 1.9169 - val_accuracy: 0.2401\n",
      "Epoch 76/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7355 - accuracy: 0.3333 - val_loss: 1.9106 - val_accuracy: 0.2324\n",
      "Epoch 77/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7322 - accuracy: 0.3320 - val_loss: 1.9195 - val_accuracy: 0.2277\n",
      "Epoch 78/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7156 - accuracy: 0.3397 - val_loss: 1.9228 - val_accuracy: 0.2365\n",
      "Epoch 79/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7339 - accuracy: 0.3224 - val_loss: 1.9151 - val_accuracy: 0.2308\n",
      "Epoch 80/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7171 - accuracy: 0.3446 - val_loss: 1.9088 - val_accuracy: 0.2452\n",
      "Epoch 81/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7150 - accuracy: 0.3500 - val_loss: 1.9234 - val_accuracy: 0.2324\n",
      "Epoch 82/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7135 - accuracy: 0.3502 - val_loss: 1.9040 - val_accuracy: 0.2416\n",
      "Epoch 83/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7546 - accuracy: 0.3238 - val_loss: 1.9298 - val_accuracy: 0.2365\n",
      "Epoch 84/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7446 - accuracy: 0.3144 - val_loss: 1.9525 - val_accuracy: 0.2138\n",
      "Epoch 85/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7173 - accuracy: 0.3442 - val_loss: 1.9036 - val_accuracy: 0.2509\n",
      "Epoch 86/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7187 - accuracy: 0.3425 - val_loss: 1.9467 - val_accuracy: 0.2205\n",
      "Epoch 87/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7294 - accuracy: 0.3291 - val_loss: 1.9503 - val_accuracy: 0.2154\n",
      "Epoch 88/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1.7255 - accuracy: 0.3325 - val_loss: 1.9211 - val_accuracy: 0.2272\n",
      "Epoch 89/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7368 - accuracy: 0.3224 - val_loss: 1.9398 - val_accuracy: 0.2318\n",
      "Epoch 90/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7175 - accuracy: 0.3429 - val_loss: 1.9110 - val_accuracy: 0.2329\n",
      "Epoch 91/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7020 - accuracy: 0.3425 - val_loss: 1.9181 - val_accuracy: 0.2349\n",
      "Epoch 92/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7253 - accuracy: 0.3296 - val_loss: 1.9135 - val_accuracy: 0.2401\n",
      "Epoch 93/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7258 - accuracy: 0.3370 - val_loss: 1.9119 - val_accuracy: 0.2437\n",
      "Epoch 94/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7288 - accuracy: 0.3261 - val_loss: 1.9336 - val_accuracy: 0.2262\n",
      "Epoch 95/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7435 - accuracy: 0.3329 - val_loss: 1.9416 - val_accuracy: 0.2303\n",
      "Epoch 96/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7222 - accuracy: 0.3393 - val_loss: 1.9127 - val_accuracy: 0.2344\n",
      "Epoch 97/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7369 - accuracy: 0.3278 - val_loss: 1.9443 - val_accuracy: 0.2324\n",
      "Epoch 98/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7172 - accuracy: 0.3340 - val_loss: 1.9271 - val_accuracy: 0.2339\n",
      "Epoch 99/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7247 - accuracy: 0.3470 - val_loss: 1.9234 - val_accuracy: 0.2267\n",
      "Epoch 100/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7097 - accuracy: 0.3488 - val_loss: 1.9122 - val_accuracy: 0.2457\n"
     ]
    }
   ],
   "source": [
    "train_data, val_data, test_data, encoder = gs.preprocessing(full_features, tracks, genres, features, \n",
    "                                                            training, validation, test)\n",
    "model = gs.build_model(train_data, layers.value)\n",
    "gs.train_model(model, train_data, val_data, epochs.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733f74c9",
   "metadata": {},
   "source": [
    "## 5. Testing the Model\n",
    "\n",
    "Once your model has finished training, you can test it by running the cell below. The model will use the test dataset as a way of checking its accuracy. Once it's done testing, it'll print out the model's accuracy as well as 10 of the predictions it made on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26d8270d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Results:\n",
      "17/17 - 0s - loss: 1.9967 - accuracy: 0.2287\n",
      "\n",
      "Predictions:\n",
      "Song 1\n",
      "Prediction: Rock\n",
      "Confidence: 29.05%\n",
      "Result: FAILURE\n",
      "\n",
      "Song 2\n",
      "Prediction: Folk\n",
      "Confidence: 21.11%\n",
      "Result: FAILURE\n",
      "\n",
      "Song 3\n",
      "Prediction: Rock\n",
      "Confidence: 39.23%\n",
      "Result: FAILURE\n",
      "\n",
      "Song 4\n",
      "Prediction: Rock\n",
      "Confidence: 22.94%\n",
      "Result: FAILURE\n",
      "\n",
      "Song 5\n",
      "Prediction: Rock\n",
      "Confidence: 35.41%\n",
      "Result: FAILURE\n",
      "\n",
      "Song 6\n",
      "Prediction: Rock\n",
      "Confidence: 34.55%\n",
      "Result: FAILURE\n",
      "\n",
      "Song 7\n",
      "Prediction: Rock\n",
      "Confidence: 33.16%\n",
      "Result: FAILURE\n",
      "\n",
      "Song 8\n",
      "Prediction: Instrumental\n",
      "Confidence: 32.87%\n",
      "Result: FAILURE\n",
      "\n",
      "Song 9\n",
      "Prediction: Electronic\n",
      "Confidence: 37.77%\n",
      "Result: SUCCESS\n",
      "\n",
      "Song 10\n",
      "Prediction: Rock\n",
      "Confidence: 30.15%\n",
      "Result: FAILURE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gs.test_model(model, test_data, encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c70ff54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
